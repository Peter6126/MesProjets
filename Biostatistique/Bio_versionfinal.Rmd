---
title: "Projet Biostatistique"
author: "Kuassi Pierre DOVODJI - Evencia MICHONDARD - José BANKOLE"
date: "2024-11-12"
output:
  bookdown::pdf_document2:
    toc: true
    number_sections: true
    toc_depth: 2
    df_print: paged
    latex_engine: xelatex  
---


```{r setup, include=FALSE }
knitr::opts_chunk$set(echo=FALSE, warning = FALSE, message = FALSE, results = "hide")
```

```{r }
# Importation des library
library(tidyverse)
library(nnet)
library(ggplot2)
library(corrplot)
library(pROC)
library(MASS)
library(GGally)
library(MASS)
library(nnet)
```

\newpage


# Introduction

Les pathologies orthopédiques comme la hernie discale et le spondylolisthésis posent de gros défis pour la santé publique. Ils affectent la mobilité, la qualité de vie des patients et engendrent des coûts élevés pour les soins. Il est donc important de mieux comprendre les facteurs biomécaniques et anatomiques qui contribuent à ces pathologies. \newline
Nous commencerons par des analyses exploratoires des différentes mesures effectuées, puis nous étudierons les liens entre ces mesures et les phatologies à l'aide de graphiques, de tests statistiques et de modèles.

# Objectifs

L’objectif est d’identifier si des mesures telles que l’incidence pelvienne, la lordose lombaire ou le degré de spondylolisthésis prédisent la présence d’une pathologie diagnostiquée.

# Description de la base de données

La base de données comporte 310 observations et 7 variables dont 6 variables quantitatives et une qualitative qui est notre variable d'intérèt. 

- Les variables numériques :

  - **IP**: Incidence Pelvienne du patient
  - **IB**: Inclinaison du Bassin
  - **ALB**: Angle de Lordose Lombaire
  - **PS**: Pente Sacrée( mesure numérique qui décrit l'orientation de la partie supérieure du sacrum).
  - **RP**: Rayon Pelvien 
  - **DS**: Degré de Spondylolisthesis

- Le variable qualitative :

  - **Pathologie** : Indique la classification clinique du patient ('Normal', 'Hernie', ou 'Spondylolisthesis').

```{r results='markup'}
# importation de la base de données
data <- read.csv("Orthopédie/Orthopédie.csv") 
# inspection de la data 
str(data)  
```

# Les valeurs manquantes

```{r}
# visualisation des valeurs manquantes
naniar::vis_miss(data) 
```

L'analyse de la base de données montre qu'elle est complète et ne contient aucune valeur manquante, ce qui garantit l'intégrité des données pour les analyses.

# Statistique descriptives
A cette étape, nous donnons une première vue de la répartition des données.
## Résumé statistiques

```{r, results='markup'}
data$Pathologie<- as.factor(data$Pathologie )
summary(data)
```

Pour la variable DS, certaines valeurs semblent anormales. Nous la gardons pour l’instant, mais nous pourrions la supprimer si nous obtenons plus d’informations.


## Distribution des variables quantitatives

```{r }
data %>%
  dplyr::select(-Pathologie) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valeur") %>%
  ggplot(aes(x = Valeur)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  facet_wrap(~Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Distribution des variables quantitatives")

```

La distribution des variables de la base de données semble majoritairement normale. Cependant, la variable *DS* se distingue par une distribution qui s'apparente davantage à une exponentielle, ce qui pourrait indiquer une asymétrie ou une concentration des valeurs vers un extrême.

## Barplot de la variable quantitative

```{r}
ggplot(data, aes(x=Pathologie, fill=Pathologie)) + 
  geom_bar() + 
  geom_text(stat='count', aes(label=..count..), vjust=-0.5) +  
  theme_minimal() + 
  labs(title = "Répartition des pathologies") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Les effectifs des trois catégories de pathologie sont inégalement répartis : 60 observations pour la Hernie, 100 pour la catégorie normale et 150 pour la Spondylolisthesis, qui est la plus représentée. Cette différence de taille d’échantillon peut influencer les analyses statistiques. De plus, la disparité des effectifs pourrait biaiser certaines conclusions, rendant nécessaire un ajustement par des méthodes comme le rééchantillonnage.

## Boxplot des variables par type de pathologie

```{r }
data %>%
  pivot_longer(cols = c("IP", "IB", "ALB", "PS", "RP", "DS"),
               names_to = "Variable", values_to = "Valeur") %>%
  ggplot(aes(x = Pathologie, y = Valeur, fill = Pathologie)) +
  geom_boxplot() +
  facet_wrap(~Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Boxplot des variables par type de pathologie")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

L'analyse des boxplots montre que les variables: 

- **ALB, IP, PS** : La médiane et l'étendue des valeurs sont plus élevées pour les patients atteints de **Spondylolisthesis** que pour les autres groupes.

- **DS** : Cette variable présente une distribution fortement asymétrique, avec des valeurs très faibles pour **Hernie** et **Normal**, mais des valeurs beaucoup plus dispersées pour **Spondylolisthesis**.

- **IB et RP** : Les distributions semblent plus homogènes entre les pathologies, bien que **Spondylolisthesis** affiche une plus grande dispersion.  

**Conclusion**:

Certaines variables, comme **DS** et **ALB**, montrent des différences marquées entre les pathologies, ce qui pourrait les rendre intéressantes pour la classification des patients.

## Test statistique

### Vérifiecation la normalité des données

Utilisons le qqplot pour chaque variable et chaque groupe de pathologie pour vérifié la normalité.

```{r  results='markup'}
library(ggpubr)
library(gridExtra)
library(grid)

variables <- colnames(data)[sapply(data, is.numeric)] # Variables numériques
plots <- list()
index <- 1 

for (var in variables) {
  for (patho in unique(data$Pathologie)) {
    subset_data <- data[data$Pathologie == patho, var, drop = FALSE]
    
    p <- ggqqplot(subset_data[[var]]) +
      ggtitle(paste("QQ-plot de", var, "\n(", patho, ")")) +
      theme_minimal()
    
    plots[[index]] <- p 
    index <- index + 1
  }
}

total_plots <- length(plots)
half_plots <- ceiling(total_plots / 2)  # Moitié des graphiques

# Première page
grid.arrange(grobs = plots[1:half_plots], nrow = 3, ncol = 3)
# Seconde page
grid.arrange(grobs = plots[(half_plots + 1):total_plots], nrow = 3, ncol = 3)

```
 
On remarque que pour chaque groupe de pathologie, toutes les variables suivent une distribution normale.

### Test de Levene

Nous allons utilser le test de Levene pour vérifier si la variabilité au sein des groupes est homogène.

#### Hypothèses pour le test de Levene :

- **Hypothèse nulle (H₀)** :  
  Il n'y a pas de différence significative dans les variances entre les groupes. Autrement dit, les variances sont égales pour toutes les catégories de la variable `Pathologie`.

  $$
  H_0 : \sigma^2_h = \sigma^2_n  = \sigma^2_s
  $$
  où $\sigma^2_h = \sigma^2_n  = \sigma^2_s$ sont les variances des groupes définis par la variable `Pathologie` c'est à dire `Normal`,`Hernie`, `Spondylolisthesis`.

- **Hypothèse alternative (H₁)** :  

  Il existe une différence significative dans les variances entre au moins deux groupes (la variabilité au sein des groupes n'est pas homogène).

  $$
  H_1 : \text{Au moins deux variances sont différentes.}
  $$



```{r results='markup'}
library(car)

# Créer un tableau vide pour stocker les résultats
results <- data.frame(Métrique = character(), P_value = numeric(), Commentaire = character(),
                      stringsAsFactors = FALSE)

data$Pathologie <- as.factor(data$Pathologie)
# Appliquer le test de Levene et stocker les résultats

for (var in variables) {
  # Effectuer le test de Levene
  test_result <- leveneTest(as.formula(paste(var, "~ Pathologie")), data=data)
  
  #Extraire la p-value
  p_value <- test_result$`Pr(>F)`[1]
  
  if (p_value < 0.05) {
    commentaire <- "Différence significative entre les groupes"
  } 
  else {
    commentaire <- "Pas de différence significative"
  }
  
  results <- rbind(results, data.frame(Métrique = var, P_value = p_value, Commentaire = commentaire))
}

# Afficher les résultats avec knitr::kable
knitr::kable(results, col.names = c("Variables", "P-value", "Commentaire"), format = "markdown")
```

Étant donné que nous observons une variabilité entre les variances des groupes pour toutes les variables, ce qui viole l'une des hypothèses fondamentales de l'ANOVA classique, nous ne pourrons pas utiliser ce test pour comparer les moyennes. Par conséquent, nous allons recourir au test de **Kruskal-Wallis**, également appelé **ANOVA unidirectionnelle sur rangs**, qui est une alternative non paramétrique et ne nécessite pas l'hypothèse d'homogénéité des variances.

#### Test Kruskal-Wallis

##### Hypothèses pour le test de Kruskal-Wallis :

- **Hypothèse nulle (H₀)** :  
  Il n'y a pas de différence significative dans les distributions des groupes. Autrement dit, les différentes catégories de la variable `Pathologie` proviennent de populations ayant des distributions similaires (les médianes des groupes sont égales).

  $$
  H_0 : \text{Les distributions des groupes sont identiques.}
  $$

- **Hypothèse alternative (H₁)** :  
  Il existe au moins une différence significative dans les distributions des groupes. Cela signifie que les groupes ne proviennent pas tous de populations ayant des distributions similaires (les médianes des groupes ne sont pas égales).

$$
  H_1 : \text{Au moins une des distributions des groupes est différente.}
$$


```{r  results='markup'}
# Créer un tableau vide pour stocker les résultats
results_krust <- data.frame(Métrique = character(), P_value = numeric(), Commentaire = character(),
                      stringsAsFactors = FALSE)

data$Pathologie <- as.factor(data$Pathologie)

# Appliquer le test de Kruskal-Wallis et stocker les résultats
for (var in variables) {
  # Effectuer le test de Kruskal-Wallis
  test_result <- kruskal.test(as.formula(paste(var, "~ Pathologie")), data=data)
  
  # Extraire la p-value
  p_value <- test_result$p.value
  
  # Ajouter un commentaire basé sur la p-value
  if (p_value < 0.05) {
    commentaire <- "Différence significative entre les groupes"
  } else {
    commentaire <- "Pas de différence significative"
  }
  
  # Ajouter le résultat au tableau
  results_krust <- rbind(results, data.frame(Métrique = var, P_value = p_value, Commentaire = commentaire))
}

# Afficher les résultats avec knitr::kable
knitr::kable(results_krust[1:6,], col.names = c("Variables", "P-value", "Interprétation"), format = "markdown")

```

**Conclusion générale** :  

Étant donné que la **p-value** pour toutes les variables est inférieure à 0.05, nous rejetons l'hypothèse nulle pour chaque test de Kruskal-Wallis, ce qui signifie qu'il existe des **différences significatives** entre les distributions des groupes définis par `Pathologie`. En d'autres termes, chaque variable montre des variations notables entre les différentes pathologies, ce qui suggère que les groupes de `Pathologie` ont des comportements distincts pour toutes les métriques mesurées. Ce que nous allons essayer de vérifier avec quelques modèles statistiques.

```{r}
data$Pathologie<-factor(data$Pathologie, 
       levels = c("Normal", "Hernie", "Spondylolisthesis"), ordered = TRUE)
```

```{r}
ggpairs(data[,1:6] )
```

En analysant le nuage de points et la matrice de corrélation, nous constatons une forte relation positive entre l'incidence pelvienne et deux variables clés : l'angle de lordose lombaire et la pente sacrée. Dans notre cas, la corrélation est d'autant forte entre l'incidence pelvienne et la pente sacrée et de l'ordre de 0.81. \newline

Cette observation est confirmée par la littérature scientifique. Par exemple, l'article "Valeur physiologique des paramètres pelviens et rachidiens : étude chez 300 sujets asymptomatiques" publié sur EM-Consulte met en évidence une corrélation significative entre la pente sacrée et l'incidence pelvienne (r = 0,8). Aussi, on trouve dans la littérature la relation $IP = PS + VP.$\newline
Ainsi, la question que l'on se pose à cette étape est la conséquence que cela aura si l'on gardait les deux variables dans la suite de notre étude. \newline

Nous réalisons une première étude en conservant l’ensemble des variables. Ensuite, nous menons deux autres analyses, chacune excluant successivement l’une des variables.\newline
La variable d'intérèt concerne les différentes pathologies que l'on remarque en s'intéressant aux variables explicatives. Comme pathologies, nous avons **Hernie**, **Normal** et **Spondylolisthesis**. \newline
En se basant sur la gravité des pathologies (du moins au plus problématique), un ordre naturel se dessine:\newline
- Normal: Aucune douleur.\newline
- Hernie: Souvent douloureux mais pouvant être traité.\newline
- Spondylolisthésis: Plus grave, pouvant nécessiter une intervention chirurgicale si sévère.\newline
*Conclusion*: Si on suppose que "Spondylolisthésis" est une évolution plus grave que "Hernie" et que "Normal" est l’état initial, alors une régression polytomique ordonnée est plus appropriée. \newline
Cependant, si on s'intéresse à leur origine:\newline
- Normal: Aucune atteinte.\newline
- Hernie: Problème mécanique.\newline
- Spondylolisthésis: Atteinte structurelle.\newline
*Conclusion*: En s'intéressant à leur origine les trois catégories sont sans ordre précis. Ainsi, une régression polytomique non ordonnée est conseillée.

# Modèles

## Données d'apprentissage et de test

Nous divisons le jeu de donnée en deux parties: \newline
- Une partie entrainement qui permettra d'entrainer les modèles\newline
- Une partie test pour évaluer la qualité des modèles.

```{r}
set.seed(2)
n<- sample(nrow(data), nrow(data)*0.75)
train<- data[n,]
test<- data[-n,]
```


## Modèle logistique ordonné
 
```{r}
train1 <- train %>% dplyr::select(-IP)
train2<- train %>% dplyr::select(-PS)
```

### Avec toutes les variables explicatives

```{r results='markup'}
rec1<- polr(Pathologie~IP+IB+ALB+PS+RP+DS, data=train, Hess = TRUE)
summary(rec1)
```

- **Interpretation**: Le modèle pose un problème car certains coefficients, comme ceux de `IP`, `IB` et `PS`, sont **beaucoup trop grands**  de l’ordre de $10^7$. Cela peut indiquer un **problème de forte corrélation entre les variables**. À l’inverse, `ALB` a un **effet très faible et non significatif**, ce qui signifie qu’elle n’a probablement pas d’impact sur `Pathologie`. Même si `RP` et `DS` semblent avoir un effet significatif, les valeurs extrêmes des autres coefficients rendent le modèle **instable et difficile à interpréter**. Cela confirme nos conclusions précédentes. Pour améliorer le modèle, nous allons tester des versions sans inclure `IP` et `PS` en même temps, car nous avons vu qu'elles sont très corrélées. Cela aidera à réduire les problèmes de multicolinéarité et à rendre le modèle plus fiable.

### Modèle avec la variable `PS` sans `IP`

```{r results='markup'}
rec2<- polr(Pathologie~IB+ALB+PS+RP+DS, data=train1, Hess = TRUE)
ctable2 <- coef(summary(rec2))
p2 <- pnorm(abs(ctable2[, "t value"]), lower.tail = FALSE) * 2
ctable2 <- cbind(ctable2, "p value" = p2)
ctable2
```
On constate déjà qu'en retirant la varible `IP` les estimations des paramètres semblent être bonne.\newline

 **Interprétation** : \newline

En analysant les coéficients et les p_values, on peut déduire :\newline

  -`IB` a un effet légèrement positif mais faiblement significatif , ce qui signifie qu’une augmentation de IB pourrait légèrement diminuer la gravité de la pathologie, mais l'effet reste incertain. 

  - `ALB` a un effet négatif faible et non significatif, ce qui indique qu’il n'a probablement pas d’impact notable sur Pathologie.

  -`PS` a un effet négatif mais non significatif , ce qui suggère qu’il n’influence pas fortement la sévérité de la pathologie. 

  -`RP` a un effet significativement négatif, ce qui signifie que plus `RP` est élevé, plus la pathologie est sévère. 

  -`DS` est hautement significatif et positif, ce qui indique que plus `DS` diminue, plus la pathologie est grave.


 **Intervale de confiances** \newline


```{r, results='markup'}
# Intervalle de confiance 
confint(rec2)
```

Les intervalles de confiance nous donnent une idée de l'incertitude des effets estimés :  
  
  - `RP` a un intervalle entièrement négatif (`[-0.113, -0.029]`) qui contient le paramètre estimé, confirmant son effet aggravant. Autrement dit, toutes choses égales par ailleurs, une augmentation de `RP (Rayon pelvien) ` de 10 mm augmente le risque de changer de catégorie de pathologie d'au plus 3. 

  - `DS` a un intervalle entièrement positif (`[0.188, 0.298]`) qui contient le paramètre estimé, confirmant son effet protecteur. Autrement dit toutes choses égales par ailleurs, une augmentation de `DS (Degré de spondylolisthesis)` de 5°  dimunie le risque de gravité de la pathologie  d'au moins 0.22.   

  - `IB`, `ALB`, et `PS` ont des intervalles qui incluent **zéro**. De plus $ exp(-coef) \approx 1 $ ce qui signifie que une augmentation de leur mesure n'a pas d'effet sur le changement de la gravité de la maladie toutes choses égales par ailleurs.
 
 **Conclusion**  

Toutes choses égales par ailleurs, les résultats montrent que **RP augmente la gravité de la pathologie**, tandis que **DS la diminue fortement**. En revanche, les effets de `IB`, `ALB` et `PS` restent **incertains ou faibles**. 

**Prévison** 

```{r results='markup'}
pred2 <- predict(rec2, newdata = test)
conf_matrix2<- table(Predicted = pred2, Actual = test$Pathologie)

#Calcul de l'exactitude
accuracy2 <- sum(diag(conf_matrix2)) / sum(conf_matrix2)
print(paste("Accuracy:", round(accuracy2 * 100, 2), "%"))
knitr::kable(conf_matrix2,format = "markdown")
```

On constate que: 

- Le modèle a une exactitude de 79.49 %, ce qui signifie que le modèle prédit correctement 79.49 % des observations de test.

- Le modèle semble bien fonctionner pour la classe Spondylolisthesis avec une grande précision, mais il a un certain taux d'erreur pour les classes "Normal" et "Hernie", avec des confusions entre ces deux classes.

- La classe "Hernie" souffre d'un nombre significatif de faux positifs.


### Modèle avec la variable `IP` sans `PS`

```{r results='markup'}
rec3<- polr(Pathologie~IP+IB+ALB+RP+DS, data=train2, Hess = TRUE)
ctable3 <- coef(summary(rec3))
p3 <- pnorm(abs(ctable3[, "t value"]), lower.tail = FALSE) * 2
ctable3 <- cbind(ctable3, "p value" = p3)
ctable3

```



 **Interprétation ** : La(es) variable(s): 

  - **Inclinaison du bassin (`IB`)** : A un effet positif significatif, suggérant qu'une augmentation de l'inclinaison du bassin diminue le risque de changer de catégorie de pathologie.
  
  - **Rayon pelvien (`RP`)** : A un effet négatif significatif, indiquant que lorsque le rayon pelvien augmente, diminue la risque de changer de catégorie de pathologie.
  
  - **Degré de spondylolisthesis (`DS`)** : A un effet positif très significatif, ce qui signifie qu'un degré plus élevé de spondylolisthesis est associé à une pathologie moins sévère.
  
  - **Incidence pelvienne (`IP`)** et **Angle de lordose lombaire (`ALB`)** n'ont pas d'effet significatif sur la pathologie. 


 
 **Intervalle de confinance**

```{r results='markup'}
confint(rec3)
```

Les intervalles de confiances nous confime des commentaires:

  - **RP (Rayon pelvien)** : L'intervalle de confiance pour `RP` est entièrement négatif (**[-0.113, -0.029]**) qui contient le paramètre estimé, ce qui indique qu'une augmentation du rayon pelvien est associée à une probabilité élevée de passer à une pathologie plus grave. Autrement dit, toutes choses égales par ailleurs, une augmentation du rayon pelvien de 10mm augmente d'au moins 3 le risque de progression vers une pathologie plus sévère.

  - **DS (Degré de spondylolisthesis)** : L'intervalle de confiance pour `DS` est entièrement positif (**[0.188, 0.298]**) qui contient le paramètre estimé, ce qui signifie qu'une augmentation du degré de spondylolisthesis est associée à une probabilité  élévée de passer à une pathologie moins grave. Autrement dit, toutes choses égales par ailleurs, une augmentation du degré de spondylolisthesis de 5° diminue d'au moins 0.23 le risque de progression vers une pathologie plus sévère.

  - **IB (Inclinaison du bassin)**, **ALB (Angle de lordose lombaire)** et **PS (Pente sacrée)** : Les intervalles de confiance pour ces variables incluent **zéro**, ce qui signifie qu'elles n'ont **pas d'effet significatif** sur la gravité de la pathologie. Ces variables ne sont pas statistiquement significatives dans ce modèle, ce qui suggère qu'elles n'influencent pas de manière mesurable le passage entre les catégories de pathologie. Aussi en l'intervalle de confiance de **ALB**, on constate que, toutes choses égales par ailleurs une augmentation de **ALB** n'a quasiment pas d'effet sur le changement de catégorie de la pathologie.



**Prévison**

```{r results='markup'}
pred3 <- predict(rec3, newdata = test)
conf_matrix <- table(Predicted = pred3, Actual = test$Pathologie)

#Calcul de l'exactitude
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
knitr::kable(conf_matrix,format = "markdown")
```
On constate que: 

- Le modèle a une exactitude de 79.49 %, ce qui signifie que le modèle prédit correctement 79.49 % des observations de test.

- Le modèle semble bien fonctionner pour la classe Spondylolisthesis avec une grande précision, mais il a un certain taux d'erreur pour les classes "Normal" et "Hernie", avec des confusions entre ces deux classes.

- La classe "Hernie" souffre d'un nombre significatif de faux positifs (classées comme "Normal").

### Résumé - conclusion

Les variables `IP`(Incidence pelvienne du patient) et `PS`(Pente sacrée) n'ont pas montré d'impact significatif sur le modèle, comme le confirme l'intervalle de confiance des coefficients, qui inclut zéro pour ces deux variables. Cela signifie que, dans ce contexte particulier, l'inclusion de ces variables ne contribue pas à améliorer la capacité prédictive du modèle. De plus, les performances des modèles avec et sans ces variables sont identiques sur l'ensemble de test, ce qui suggère qu'elles sont redondantes ou non significatives pour la tâche de classification. Nous allons donc supprimer les deux variables du modèle.

### Modèle sans les variables `IP` et `PS`

```{r results='markup'}
rec4<- polr(Pathologie~IB+ALB+RP+DS, data=train, Hess = TRUE)
ctable4 <- coef(summary(rec4))
p4 <- pnorm(abs(ctable4[, "t value"]), lower.tail = FALSE) * 2
ctable4 <- cbind(ctable4, "p value" = p4)
ctable4
confint(rec4)
```


- **Interpretation**: En analysant les intervalles de confiance et les p_values, on déduit que la variables:

  - **IB (Inclinaison du bassin)** : Cette variable a un effet positif significatif sur la progression de la pathologie. Cela signifie que toutes choses égales par ailleurs, une augmentation de l'inclinaison du bassin  de 5° va entrainer une diminution du risque de transition vers une pathologie plus faible d'au plus 0.95.
  
  - **ALB (Angle de lordose lombaire)** : Cette variable a un effet négatif , indiquant que toutes choses égales par ailleurs, un angle de lordose plus élevé est associé à une augmentation du risque de progression vers une pathologie plus grave.

  - **RP (Rayon pelvien)** : Cette variable a un effet négatif significatif. Cela suggère, toutes choses égale par ailleurs, un rayon pelvien plus grand est lié à une probabilité plus élevée de progression vers une pathologie plus sévère.

  - **DS (Degré de spondylolisthesis)** : Cette variable montre un effet positif très significatif , indiquant, toutes choses égales par ailleurs, un degré plus élevé de spondylolisthesis diminue le risque de progression vers une pathologie plus grave.


En résumé, les variables **IB**, **ALB**, **RP** et **DS** ont un impact significatif sur la progression de la pathologie, tandis que la comparaison entre **Hernie** et **Spondylolisthesis** n'est pas significative.\newline

En résumé, les principales variables influençant la pathologie sont l'inclinaison du bassin, le rayon pelvien, et le degré de spondylolisthesis, tandis que l'incidence pelvienne et l'angle de lordose lombaire n'ont pas d'impact important dans ce modèle.

```{r results='markup'}

pred4 <- predict(rec4, newdata = test)
conf_matrix4 <- table(Predicted = pred4, Actual = test$Pathologie)

#Calcul de l'exactitude
accuracy4 <- sum(diag(conf_matrix4)) / sum(conf_matrix4)
print(paste("Accuracy:", round(accuracy4 * 100, 2), "%"))
knitr::kable(conf_matrix4,format = "markdown")
```

La précision globale a diminué de 79.49% à 74.36%, ce qui suggère que la nouvelle configuration du modèle, même avec des ajustements sur les variables, a légèrement dégradé les performances de classification, surtout dans la matrice de confusion entre `Normal` et `Hernie`. Cependant, la classification de `Spondylolisthesis` semble robuste avec aucune confusion.


## Modèles polytomiques non ordonnés

Dans cette section, nous considérons les différentes pathologies comme des catégories sans ordre spécifique. Étant donné que nous avons précédemment observé que l'inclusion simultanée des variables IP et PS, fortement corrélées, entraîne de mauvaises estimations des paramètres du modèle, nous construirons des modèles en excluant ces deux variables.\newline

Nous mettons en place le modèle


```{r results='markup'}
rec5 <- multinom(Pathologie ~ IB + ALB  + RP + DS, data = train)
summary(rec5)
```

```{r results='markup'}
confint(rec5)
```

Une des particularités de la régression logistique multinomiale est qu’elle produit une série de coefficients pour chaque modalité de la variable d’intérêt (sauf la modalité de référence). Ici, nous aurons donc une série de coefficients pour celles et ceux qui dont la pathologie est Hernie (comparés à la modalité Normal) et une série de coefficients pour celles et ceux qui dont la pathologie est Spondylolisthesis (comparés aux aussi à la modalité Normal).\newline

En analysant les intervalles de confiance des coefficients, nous constatons que l'interprétation des effets varie en fonction de la pathologie considérée. Or, les coefficients devraient refléter le même effet en fixant une modalité de référence. Cette incohérence suggère que traiter les différentes pathologies comme des catégories sans ordre n'est pas l'approche la plus appropriée.



```{r, results='markup'}
resume <- rbind(AIC(rec2), AIC(rec3),AIC(rec4)) 
resume <- cbind(resume, rbind(accuracy2, accuracy, accuracy4))
rownames(resume) <- c("Modèle2", "Modèle3","Modèle4")
knitr::kable(resume,  col.names=c('AIC', 'Exactitude'), format = "markdown")
```


Pour des raisons de simplicité et en raison de l'impact moindre des variables **IP** et **PS**, le modèle 4 (sans les variables **IP** et **PS**) a été choisi comme le meilleur modèle, bien que tous les modèles présentent des précisions similaires.

## Importances des variables 

```{r }
importance <- data.frame(Variable = c('IB', 'ALB','RP','DS'),
                         Coefficient = coef(rec4))
ggplot(importance, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
  geom_bar(stat = "identity", fill = "blue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Importance des variables dans le modèle",
       x = "Variables",
       y = "Coefficients")

```

Le **degré de spondylolisthesis (DS)** est la variable la plus déterminante dans la progression de la pathologie, tandis que **IB, ALB et RP** ont un effet plus modéré. Cela suggère que DS devrait être un facteur clé à surveiller dans l’évaluation du risque. L’influence des autres variables reste pertinente, mais leur impact est moins prononcé.

# Conclusion 

En conclusion, cette étude a permis d’analyser les facteurs influençant la progression des pathologies vertébrales à l’aide d’une régression polytomique ordinale. Les résultats montrent que le **degré de spondylolisthesis (DS)** est le facteur le plus déterminant, tandis que d’autres variables comme **IB, ALB et RP** ont un impact plus modéré. Le choix du modèle optimal a été guidé par la simplicité et la significativité des variables, aboutissant à la sélection du modèle excluant **IP et PS**. Bien que tous les modèles testés présentent des performances similaires, cette approche permet une meilleure interprétation clinique et une utilisation plus efficace des variables clés pour le diagnostic et la prise en charge des patients.

\newpage

# Annexe : Code R

```{r, ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
