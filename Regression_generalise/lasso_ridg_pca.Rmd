---
title: "TP Note 1"
author: "Kuassi Pierre"
date: "2024-09-23"
output: pdf_document
---

```{r}
# importation des données
df <- read.table("/Users/peter/Desktop/Master 2 /UFC/Apprentisage/Goga/TP/graisse2.txt", header = TRUE)
```

## R Markdown

```{r}
str(df)
summary(df)
```

```{r}
library(naniar)
vis_miss(df)
```

## Including Plots

```{r}
correlation <- cor(df)
corrplot::corrplot(correlation, method = "circle", type = "lower")
```
## Apprentissage validation

```{r}
library(Matrix)
X <- model.matrix(graisse~., df)[,-1]
y <- df$graisse

set.seed(22)
train <- sample(1:nrow(X), 0.70*nrow(X))
ytest <- y[-train]
Xtest <- X[-train,]

vect.lambda <-10^seq(-3, 4, length= 80)

library(glmnet)
model.ridge.train <- glmnet(X[train,], y[train], alpha = 0, lambda = vect.lambda, nfolds = 5)

```


# determinons le meilleur avec la validation croisé par bloc

```{r}
model.ridge.cv <- cv.glmnet(X[train,],y[train], alpha=0, lambda = vect.lambda)
plot(model.ridge.cv)
lambda.optimal <- model.ridge.cv$lambda.min

```
```{r}
ypred <- predict(model.ridge.cv, newx = Xtest, s ="lambda.min" )
mean((ytest - ypred)^2)
```
# Methode 2
```{r}
pred <- predict(model.ridge.train, newx =Xtest)
Y <- rep(ytest, length(vect.lambda)) 
r <- (Y-pred)^2
MSE <- apply(r, 2, mean )
lambda.opt <- model.ridge.train$lambda[which.min(MSE)]
```



Ici pour determiner la meilleur $\lambda_{opt}$ on calcule le $MSE (Mean Squared Error)$  sur le groupe de validation pour évaluer la performance du modèle. Le $MSE$ minimal $MSE_{min}$ correspond la valeur optimale de $\lambda$.



# Regression en composantes principales

Ici nous realisons la prédiction de la variable graisse en utilisant la regression sur Regression sur composantes principales. 

```{r}
library(pls)
mod_pcr<- pcr(graisse~., data=df,  center=T, scale=T , validation = "none")
plot(RMSEP(mod_pcr),legend="topright",main="")
```
Le graphique ci-dessus sous nous montre  l'evolution de l'erreur quadratique moyenne en fonction du nombre de composante principale, nous avons 14 composantes principales, il sera question maintenant de determiner le meilleur modèle c'est-à-dire le nomnbre composante principale a partier de laquelle on observe une décroissance lente de l'erreur quadratique moyenne pour cela nous allons effectuer la validation croisé et utilisé la repartition des données précedement.

```{r}
cv.mod_pcr  <- pcr(graisse~., data=df, center=T, scale=T , validation = "CV",  subset=train,)
validationplot(cv.mod_pcr, val.type="MSEP")
summary(cv.mod_pcr)
```

En analysant le graphe  et la sortie on constate avec 5 composantes principales on explique près 90%  de la variance et également à partir de 5 composantes le l'erreur quadratique diminue tres lentement. Donc on peu prendre p = 5.

```{r}
pred.pcr <- predict(cv.mod_pcr,df[test,],ncomp=5)
mse.pcr.optimal <- mean((pred.pcr-ytest)^2)
cat("MSE_min= ", mse.pcr.optimal)
```
